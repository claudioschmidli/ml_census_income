{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Income Dataset a.k.a \"Census Income\"\n",
    "### _Advanced Machine Learning FHNW Brugg_\n",
    "Claudio Schmidli\n",
    "\n",
    "Date: 25.08.2022\n",
    "### Task \n",
    "Predict whether income exceeds $50K/yr based on census data. Also known as [Census Income\" dataset](https://www.kaggle.com/datasets/rdcmdev/adult-income-dataset?select=adult.data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My code is splitted into the following parts:\n",
    "- Exploratory Data Analysis (<a href=\"EDA.ipynb\">EDA.ipynb</a>)\n",
    "- Investigation of feature importance (<a href=\"Feature_Importance.ipynb\">Feature_Importance.ipynb</a>)\n",
    "- Training of a logistic regression model (<a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>)\n",
    "- Training of a boosted trees model (<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)\n",
    "- Training of a model using AutoML (<a href=\"AutoML.ipynb\">AutoML.ipynb</a>)\n",
    "- Functions and classes for data processing (<a href=\"modules/preprocess.py\">modules/preprocess.py</a>)\n",
    "- Functions and classes for data visualizations (<a href=\"modules/plot.py\">modules/plot.py</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment criteria of this project\n",
    "I fullfilled the expected assessment criteria as follows:\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Criteria</th>\n",
    "    <th>Implementation</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>richtiges Anwenden der Besonderheiten des data-sets</td>\n",
    "    <td> \n",
    "      <ul>\n",
    "          <li>Different missing value treatments were tested (dropping, most freq. imputation, predict missing)</li>\n",
    "          <li>Class imbalance was handled using SMOTE and model class weights</li>\n",
    "          <li>Features with low permuation importance were excluded</li>\n",
    "          <li>The redundant column education was removed because education_num contains the same in a ordered format</li>\n",
    "          <li>(see notebooks <a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>/<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Auswahl richtige loss-Funktion</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I used the f1 score to evaluate the model</li>\n",
    "          <li>This makes sense because we have imbalanced data</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Verteilung der target-Values</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I visualized the impalanced targets (see <a href=\"EDA.ipynb\">EDA.ipynb</a>)</li>\n",
    "          <li>I treated the impalanced data with SMOTE and class weights (see <a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>/<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>feature-engineering</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I tested interactions for the Logistic regression and lightgbm classifiers (see <a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>/<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>) </li>\n",
    "          <li>I created a custom transformer to generate the interactions (see <a href=\"modules/preprocess.py\">modules/preprocess.py</a>)</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>korrekte Einschätzung der Modell-Performance</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I used cross validation to estimate the performance of the model</li>\n",
    "          <li>I prevented data leakage by using pipelines and creating custom transformers (see <a href=\"modules/preprocess.py\">modules/preprocess.py</a>)</li>\n",
    "          <li>I used the imblearn library to do SMOTE withing the cross validation</li>\n",
    "          <li>I used StratifiedKFold for cross validation</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>richtiges Anwenden von feature-importance</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I used premuatation improtance to estimate the performance of a feature</li>\n",
    "          <li>I created a transformer to create interactions based on the best features (see InteractionsTransformer in <a href=\"modules/preprocess.py\">modules/preprocess.py</a>)</li>\n",
    "          <li>I visualized the feature importance in  <a href=\"Feature_Importance.ipynb\">Feature_Importance.ipynb</a></li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>grid-search: korrekte Definition des Such-Raums</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I used grid search to optimize model parameters (see <a href=\"Logisticd_regression.ipynb\">Logistic_regression.ipynb</a>/<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)</li>\n",
    "          <li>I started with the default values</li>\n",
    "          <li>I also used non linear search patterns</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Verwendung von Pipelines</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I used pipelines to generate and evaluate my models (see <a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>/<a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)</li>\n",
    "          <li>I created custom transformers to process data (see <a href=\"modules/preprocess.py\">modules/preprocess.py</a>)</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Suche nach bestem Algorithmus (Lern-Algorithmus); <br>mindestens 2 verschieden Ansätze</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "          <li>I trained a logistic regression model (see <a href=\"Logistic_regression.ipynb\">Logistic_regression.ipynb</a>)</li>\n",
    "          <li>I trained a gradient boosted tree (see <a href=\"lightgbm.ipynb\">lightgbm.ipynb</a>)</li>\n",
    "          <li>I trained a model using the AutoML toolkit <a href=\"https://auto.gluon.ai/dev/tutorials/tabular_prediction/tabular-custom-metric.html\">AutoGluon</a> (see <a href=\"AutoML.ipynb\">AutoML.ipynb</a>)</li>\n",
    "    </ul>  \n",
    "    </td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "As expected the boosted trees provided the best results:\n",
    "### <a href=\"Logistic_regression.ipynb\">Logistic_regression</a>\n",
    "- f1 score train: 0.68897\n",
    "- f1 score test: 0.67885\n",
    "\n",
    "### <a href=\"lightgbm.ipynb\">lightgbm</a>\n",
    "- f1 score train: 0.72795\n",
    "- f1 score test: 0.71947\n",
    "\n",
    "### <a href=\"AutoML.ipynb\">AutoGluon</a>\n",
    "Best model (WeightedEnsemble_L2)\n",
    "- f1 score train: 0.73069\n",
    "- f1 score test: 0.71536\n",
    "\n",
    "Second best model (LightGBM_BAG_L1)\n",
    "- f1 score train: 0.72576\n",
    "- f1 score test: 0.69749"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting models such as LightGBM, XGBoost and Catboost have long been considered best in class for tabular data. The results here confrim this statement. \n",
    "- Fortunately I got a better test core with my own lightgbm mode than the AutoML model of AutoGluon :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- How can I achive such high scores as shown in the leaderbord of [this](https://www.kaggle.com/competitions/adult-census-income/data?select=AdultCensusIncomeTest.csv) Kaggle competition?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "900aa3c88b9e523c15bd03ed94e3ffd6c7de8c1f22936e93006d5eaf906f882d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
